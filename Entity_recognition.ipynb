{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Entity recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY-Ts1z9YgQ7",
        "colab_type": "text"
      },
      "source": [
        "# Recognize named entities on Twitter with LSTMs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQhrrQy2YgQ8",
        "colab_type": "text"
      },
      "source": [
        "## DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaA5WqRcZDwc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2279988-cdf8-41e8-9e61-3afb6be73c51"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE2fUuZDYqQT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90993ae0-00c0-4fd1-8eb9-dc745568afb7"
      },
      "source": [
        "%cd /content/drive/My Drive/collab/tag prediction\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/collab/tag prediction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kopsFHQuZh-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "972b8bd4-70a7-4b60-bade-2617a1d40ff1"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/collab/tag prediction'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBwewfUJYgRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to generate tokens and tags out of text data\n",
        "def read_data(file_path):\n",
        "    tokens = []\n",
        "    tags = []\n",
        "    \n",
        "    tweet_tokens = []\n",
        "    tweet_tags = []\n",
        "    for line in open(file_path, encoding='utf-8'):\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            if tweet_tokens:\n",
        "                tokens.append(tweet_tokens)\n",
        "                tags.append(tweet_tags)\n",
        "            tweet_tokens = []\n",
        "            tweet_tags = []\n",
        "        else:\n",
        "            token, tag = line.split()\n",
        "            if (token.split(\":\")[0] == \"http\" or token.split(\":\")[0] == \"https\"):\n",
        "                tag = \"<URL>\"\n",
        "            elif(token[0] == \"@\"):\n",
        "                tag = \"<USR>\"\n",
        "            \n",
        "            tweet_tokens.append(token)\n",
        "            tweet_tags.append(tag)\n",
        "            \n",
        "    return tokens, tags"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWhxmmEWYgRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tokens, train_tags = read_data('data/train.txt')\n",
        "validation_tokens, validation_tags = read_data('data/validation.txt')\n",
        "test_tokens, test_tags = read_data('data/test.txt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMEQn9WAYgRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "6dd1b598-8c00-49ff-eca1-dbc8ba595bfe"
      },
      "source": [
        "#Example of tags and tokens\n",
        "for i in range(1):\n",
        "    for token, tag in zip(train_tokens[i], train_tags[i]):\n",
        "        print('%s\\t\\t\\t\\t%s' % (token, tag))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RT\t\t\t\tO\n",
            "@TheValarium\t\t\t\t<USR>\n",
            ":\t\t\t\tO\n",
            "Online\t\t\t\tO\n",
            "ticket\t\t\t\tO\n",
            "sales\t\t\t\tO\n",
            "for\t\t\t\tO\n",
            "Ghostland\t\t\t\tB-musicartist\n",
            "Observatory\t\t\t\tI-musicartist\n",
            "extended\t\t\t\tO\n",
            "until\t\t\t\tO\n",
            "6\t\t\t\tO\n",
            "PM\t\t\t\tO\n",
            "EST\t\t\t\tO\n",
            "due\t\t\t\tO\n",
            "to\t\t\t\tO\n",
            "high\t\t\t\tO\n",
            "demand\t\t\t\tO\n",
            ".\t\t\t\tO\n",
            "Get\t\t\t\tO\n",
            "them\t\t\t\tO\n",
            "before\t\t\t\tO\n",
            "they\t\t\t\tO\n",
            "sell\t\t\t\tO\n",
            "out\t\t\t\tO\n",
            "...\t\t\t\tO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1dRQt0TYgRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8b3ac921-11c2-49ac-aa53-f22c5deb91d3"
      },
      "source": [
        "print(f\"{train_tokens[2]}\\n{train_tags[2]}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Happy', 'Birthday', '@AshForeverAshey', '!', 'May', 'Allah', 's.w.t', 'bless', 'you', 'with', 'goodness', 'and', 'happiness', '.']\n",
            "['O', 'O', '<USR>', 'O', 'O', 'B-person', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR8VZcerYgRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR4H5aXbYgRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating dictionary\n",
        "def build_dict(tokens_or_tags, special_tokens):\n",
        "    \"\"\"\n",
        "        tokens_or_tags: a list of lists of tokens or tags\n",
        "        special_tokens: some special tokens\n",
        "    \"\"\"\n",
        "    # Create a dictionary with default value 0\n",
        "    tok2idx = defaultdict(lambda: 0)\n",
        "    idx2tok = []\n",
        "\n",
        "    n = 0\n",
        "    for item in special_tokens:\n",
        "        tok2idx[item] = n\n",
        "        n+=1\n",
        "        \n",
        "    for item in set([x for y in tokens_or_tags for x in y]):\n",
        "        tok2idx[item] = n\n",
        "        n+=1\n",
        "    idx2tok = {x:y for y,x in tok2idx.items() }\n",
        "    return tok2idx, idx2tok"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eSH3ZG5YgRP",
        "colab_type": "text"
      },
      "source": [
        " - `<UNK>` token for out of vocabulary tokens;\n",
        " - `<PAD>` token for padding sentence to the same length when we create batches of sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEFnl8w8YgRQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8eb8d21d-647c-4ede-900e-282c63c2983c"
      },
      "source": [
        "special_tokens = ['<UNK>', '<PAD>']\n",
        "special_tags = ['O']\n",
        "\n",
        "# Create dictionaries \n",
        "token2idx, idx2token = build_dict(train_tokens + validation_tokens, special_tokens)\n",
        "tag2idx, idx2tag = build_dict(train_tags, special_tags)\n",
        "\n",
        "idx2tag[1]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B-sportsteam'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ilQPywmYgRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def words2idxs(tokens_list):\n",
        "    return [token2idx[word] for word in tokens_list]\n",
        "\n",
        "def tags2idxs(tags_list):\n",
        "    return [tag2idx[tag] for tag in tags_list]\n",
        "\n",
        "def idxs2words(idxs):\n",
        "    return [idx2token[idx] for idx in idxs]\n",
        "\n",
        "def idxs2tags(idxs):\n",
        "    return [idx2tag[idx] for idx in idxs]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh-Tqv5vYgRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmVmQdxTYgRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating minibatches\n",
        "def batches_generator(batch_size, tokens, tags,\n",
        "                      shuffle=True, allow_smaller_last_batch=True):\n",
        "    \"\"\"Generates padded batches of tokens and tags.\"\"\"\n",
        "    \n",
        "    n_samples = len(tokens)\n",
        "    if shuffle:\n",
        "        order = np.random.permutation(n_samples)\n",
        "    else:\n",
        "        order = np.arange(n_samples)\n",
        "\n",
        "    n_batches = n_samples // batch_size\n",
        "    if allow_smaller_last_batch and n_samples % batch_size:\n",
        "        n_batches += 1\n",
        "\n",
        "    for k in range(n_batches):\n",
        "        batch_start = k * batch_size\n",
        "        batch_end = min((k + 1) * batch_size, n_samples)\n",
        "        current_batch_size = batch_end - batch_start\n",
        "        x_list = []\n",
        "        y_list = []\n",
        "        max_len_token = 0\n",
        "        for idx in order[batch_start: batch_end]:\n",
        "            x_list.append(words2idxs(tokens[idx]))\n",
        "            y_list.append(tags2idxs(tags[idx]))\n",
        "            max_len_token = max(max_len_token, len(tags[idx]))\n",
        "            \n",
        "        # Fill in the data into numpy nd-arrays filled with padding indices.\n",
        "        x = np.ones([current_batch_size, max_len_token], dtype=np.int32) * token2idx['<PAD>']\n",
        "        y = np.ones([current_batch_size, max_len_token], dtype=np.int32) * tag2idx['O']\n",
        "        lengths = np.zeros(current_batch_size, dtype=np.int32)\n",
        "        for n in range(current_batch_size):\n",
        "            utt_len = len(x_list[n])\n",
        "            x[n, :utt_len] = x_list[n]\n",
        "            lengths[n] = utt_len\n",
        "            y[n, :utt_len] = y_list[n]\n",
        "        yield torch.LongTensor(x), torch.LongTensor(y), lengths"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ncvdp1LYgRZ",
        "colab_type": "text"
      },
      "source": [
        "size => batch_size * max_length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srpHuuGDYgRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imgfVQdoYgRb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66cd071f-bebb-42ce-c20e-6090b2fdb7a3"
      },
      "source": [
        "tokens,tags,length = next(iter(batches_generator(batch_size=1, tokens=train_tokens, tags=train_tags)))\n",
        "tokens_,tags_,length_ = next(iter(batches_generator(batch_size=1, tokens=validation_tokens, tags=validation_tags)))\n",
        "#print(tokens.size(),tags.size(),max(length))\n",
        "print(tags,tags_)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]]) tensor([[13,  4, 15,  4,  4,  4,  4,  4, 12,  4,  4,  4, 19,  4]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ9v9Z6MYgRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self,embed_size,hidden_size, vocab_size,dropout,n_layers = 1):\n",
        "        super().__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_size =  vocab_size\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.embed = nn.Embedding(vocab_size,embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size,hidden_size,n_layers,dropout=dropout,batch_first=True,bidirectional=True)\n",
        "        self.linear = nn.Linear(2*self.hidden_size, len(idx2tag)+1)#(in_dim,out_dim)\n",
        "    \n",
        "    def forward(self,tokens,length):\n",
        "        x = self.embed(tokens)#dim: batch_size x batch_max_len x embed_size\n",
        "        #print(\"embed size\",x.shape)\n",
        "        h0 = torch.zeros(self.n_layers*2, x.size(0), self.hidden_size).cuda() # 2 for bidirection \n",
        "        c0 = torch.zeros(self.n_layers*2, x.size(0), self.hidden_size).cuda()\n",
        "        lstm_output, _ = self.lstm(x, (h0,c0)) # dim:batch_size x batch_max_len x lstm_hidden_dim(2* because bidirectional)\n",
        "        #print(\"lstm\" , lstm_output.shape)\n",
        "        lstm_output = lstm_output.reshape(-1, lstm_output.shape[2])#so each row contain one token \n",
        "        #print(\"lstm\" , lstm_output.shape)\n",
        "        output = self.linear(lstm_output)#so each token is of length of vocab  size dim: -1,no_of_tags\n",
        "        softmax_output = F.log_softmax(output,dim=1)# dim =1 means along row \n",
        "        #print(\"next check\",softmax_output.shape)\n",
        "        #output = torch.argmax(softmax_output, dim=1)\n",
        "        return  softmax_output \n",
        "        \n",
        "    "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvZ9qogAYgRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Net(embed_size = 64,hidden_size =64, vocab_size=len(token2idx),dropout=0.5,n_layers = 2)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_Dor9ekbVKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tp7h1fpbOZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "45396511-cc5d-4490-90ef-eff58f015687"
      },
      "source": [
        " net.cuda()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (embed): Embedding(26729, 64)\n",
              "  (lstm): LSTM(64, 64, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "  (linear): Linear(in_features=128, out_features=24, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywLNVHl4YgRk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86756e29-f0ea-4cc4-bf8b-50fff6452f2f"
      },
      "source": [
        "len(token2idx)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26729"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEeQ7hSGYgRm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "602ccf43-d307-47b4-de61-90b33ca47bf6"
      },
      "source": [
        "len(idx2tag)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ-wyXUXYgRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn(outputs, labels):\n",
        "    #reshape labels to give a flat vector of length batch_size*seq_len\n",
        "    labels = labels.view(-1)  \n",
        "\n",
        "    #mask out 'PAD' tokens\n",
        "    mask = (labels != 1).float()\n",
        "\n",
        "    #the number of tokens is the sum of elements in mask\n",
        "    num_tokens = int(torch.sum(mask).item())\n",
        "    #pdb.set_trace()\n",
        "\n",
        "    #pick the values corresponding to labels and multiply by mask\n",
        "    outputs = outputs[range(outputs.shape[0]), labels]*mask\n",
        "\n",
        "    #cross entropy loss for all non 'PAD' tokens\n",
        "    return -torch.sum(outputs)/num_tokens"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_Yo1ZZxYgRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss =nn.CrossEntropyLoss( )\n",
        "optimizer = torch.optim.Adam(params = net.parameters(), lr=0.03, eps=0.01)\n",
        "#optimizer = torch.optim.RMSprop(params = net.parameters(), lr=0.01)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq2kNaUsYgRs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "031de869-541b-4c00-efab-68c0970bad41"
      },
      "source": [
        "n_steps = math.ceil(len(train_tokens)/16)\n",
        "n_steps"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "363"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKY3aC6FYgRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb\n",
        "import sys"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR1DmurSYgRw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "2c7f4dfd-bd56-4add-cfb3-403c34a4685a"
      },
      "source": [
        "net.train()\n",
        "n_epoch = 5\n",
        "train_loss = 0\n",
        "validation_loss = 0\n",
        "training = []\n",
        "val = []\n",
        "for epoch in range(n_epoch):\n",
        "    train_loss = 0\n",
        "    validation_loss = 0  \n",
        "    for i ,(tokens,tags,length) in enumerate(batches_generator(batch_size=16, tokens=train_tokens, tags=train_tags),1):\n",
        "        #print(tags)\n",
        "        net.zero_grad()\n",
        "        tokens = tokens.cuda()\n",
        "        tags = tags.cuda()\n",
        "        prediction = net(tokens,length)\n",
        "        #print(prediction.shape)\n",
        "        #print([max(x.item()) for x in prediction])\n",
        "        #pdb.set_trace()\n",
        "        #training_loss = loss_fn(prediction,tags)\n",
        "        \n",
        "        training_loss = loss(prediction.view(-1,len(idx2tag)+1),tags.view(-1) )\n",
        "        train_loss += training_loss\n",
        "        # Get training statistics.\n",
        "        if(i%300 == 0):\n",
        "            print(\"training data\",\"-\"*20)\n",
        "            progress = ((epoch-1)*n_steps + i) / (n_epoch*n_steps) * 100\n",
        "            stats = '%.2f%% Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f\\n' % (progress, epoch, n_epoch-1, i, n_steps, train_loss/i, np.exp(training_loss.item()))\n",
        "            print('\\r' + stats, end=\"\")\n",
        "        \n",
        "        tokens,tags,lenght = next(iter(batches_generator(batch_size=16, tokens=validation_tokens, tags=validation_tags)))\n",
        "        tags = tags.cuda()\n",
        "        tokens = tokens.cuda()\n",
        "        prediction = net(tokens,length)\n",
        "        val_loss = loss(prediction.view(-1,len(idx2tag)+1),tags.view(-1))\n",
        "        #val_loss = loss_fn(prediction,tags)\n",
        "        # Get training statistics.\n",
        "        validation_loss += val_loss\n",
        "        if(i%300 == 0):\n",
        "            print(\"validation data\",\"-\"*20)\n",
        "            stats = '%.2f%% Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f\\n' % (progress, epoch, n_epoch-1, i, n_steps, validation_loss/i, np.exp(val_loss.item()))\n",
        "            print('\\r' + stats, end=\"\")\n",
        "            print()\n",
        "        training_loss.backward()\n",
        "        torch.nn.utils.clip_grad_value_(net.parameters(), clip_value=0.5)\n",
        "        optimizer.step()\n",
        "        \n",
        "        sys.stdout.flush()\n",
        "    val.append(validation_loss/i)\n",
        "    training.append(train_loss/i)\n",
        "        \n",
        "    \n",
        "    "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data --------------------\n",
            "\r-3.47% Epoch [0/4], Step [300/363], Loss: 0.4387, Perplexity: 1.3043\n",
            "validation data --------------------\n",
            "\r-3.47% Epoch [0/4], Step [300/363], Loss: 0.4183, Perplexity: 1.3999\n",
            "\n",
            "training data --------------------\n",
            "16.53% Epoch [1/4], Step [300/363], Loss: 0.3318, Perplexity: 1.4756\n",
            "validation data --------------------\n",
            "16.53% Epoch [1/4], Step [300/363], Loss: 0.3267, Perplexity: 1.2502\n",
            "\n",
            "training data --------------------\n",
            "36.53% Epoch [2/4], Step [300/363], Loss: 0.3018, Perplexity: 1.3000\n",
            "validation data --------------------\n",
            "36.53% Epoch [2/4], Step [300/363], Loss: 0.3004, Perplexity: 1.3789\n",
            "\n",
            "training data --------------------\n",
            "56.53% Epoch [3/4], Step [300/363], Loss: 0.2830, Perplexity: 1.1942\n",
            "validation data --------------------\n",
            "56.53% Epoch [3/4], Step [300/363], Loss: 0.2965, Perplexity: 1.5304\n",
            "\n",
            "training data --------------------\n",
            "76.53% Epoch [4/4], Step [300/363], Loss: 0.2589, Perplexity: 1.2635\n",
            "validation data --------------------\n",
            "76.53% Epoch [4/4], Step [300/363], Loss: 0.2802, Perplexity: 1.2320\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw9G51UQYgRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJxUPDvJYgR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_total = 0\n",
        "true = 0\n",
        "for tokens,tags,length in batches_generator(batch_size=16, tokens=test_tokens, tags=test_tags):\n",
        "  tokens,tags = tokens.cuda() ,tags.cuda()\n",
        "  prediction = net(tokens,length)\n",
        "  a = torch.argmax(prediction,dim = 1)\n",
        "  tags = tags.view(-1)\n",
        "  for pred,tag in zip(a,tags):\n",
        "    n_total+=1\n",
        "    if pred == tag :\n",
        "      true +=1"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXc-jQP3YgR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdc69c85-e3dc-4799-c952-472fc58ec228"
      },
      "source": [
        "true/n_total"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.931328297715549"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d07LXsjec1Se",
        "colab_type": "text"
      },
      "source": [
        "**The model have achieved 93% accuracy in 5 epochs and after 5 epoch the model starts to overfit. **\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fePJw0U5dNF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}